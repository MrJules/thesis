\chapter{Results}

This chapter aims at presenting the achieved results on the imageclef challenge, while giving some perspective on what did not work well and what worked well. Firstly in section \ref{sec:example} an example on how the system performed to a given topic is showcased while giving some insight on the differences in performance between both runs. Then, in section \ref{sec:perfomance_results} the achieved results on the challenge are presented.

\newpage
\section{System Performance Example}
\label{sec:example}


To serve the purpose of exemplifying the performance achieved on one of the given topics, topic 9 is used.\\

\textbf{Title}: "Eating pizza".

\textbf{Description}: "Find the moments when u1 was eating a pizza
while talking to one man".

\textbf{Narrative}:" To be considered relevant, the u1 must eat or
hold a pizza with a man visible in the background. The moments that
u1 was talking to more than one person are not relevant".


\subsection{Run 1 and Run 2 Image Retrieval}

The following images showcase an excerpt of the csv files generated by both runs that were sent to the imageClef evaluation platform.

The file is organized in the following way: [topic id number, image name, confidence score].


\begin{figure}[H]
  \centering
  \captionsetup{justification=centering}

  \begin{subfigure}{0.4\textwidth}
  \includegraphics[width=\textwidth]{Sections/7Results/images/topic9_results.png} 
  \caption{Run 1}
  \end{subfigure}
  \hspace{+5mm}
  \begin{subfigure}{0.385\textwidth}
  \includegraphics[width=\textwidth]{Sections/7Results/images/topic9results2.png}
  \caption{Run 2}
  \end{subfigure}
  \caption{Achieved results on topic 9 of the test topics.}
  \label{fig:runs_csv}
\end{figure}
\newpage
\subsection{Top 3 Retrieved Image on Run 1}

As it can bee seen in figure \ref{fig:runs_csv} a), the top 3 images that were retrieved for topic 9 on run 1 were:
\begin{enumerate}
  \itemsep0em
  \item b00000940\_21i6bq\_20150224\_161533e.jpg;
  \item b00000939\_21i6bq\_20150224\_161500e.jpg;
  \item B00000819\_21I6X0\_20180520\_071310E.JPG.
\end{enumerate}
 
The images can be seen below.

\begin{figure}[H]
  \centering
  \captionsetup{justification=centering}

  \begin{subfigure}{0.32\textwidth}
  \includegraphics[width=\textwidth]{Sections/7Results/images/top1.jpg} 
  \caption{Top 1}

  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
  \includegraphics[width=\textwidth]{Sections/7Results/images/top2.jpg}\hfill
  \caption{Top 2}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
  \includegraphics[width=\textwidth]{Sections/7Results/images/top3.jpg}\hfill
    \caption{Top 3}
  \end{subfigure}
  \caption{Top 3 retrieved pictures for topic 9 on run 1}
\end{figure}


\subsection{Top 3 Retrieved Images on Run 2}

Using again figure \ref{fig:runs_csv}, the top 3 images that were retrieved for topic 9 on run 2 were: 


\begin{enumerate}
  \itemsep0em
  \item B00007965\_21I6X0\_20180519\_135120E.JPG;
  \item B00000819\_21I6X0\_20180520\_071310E.JPG;
  \item B00009118\_21I6X0\_20180523\_051007E.JPG.
\end{enumerate}


The images can be seen below.
\begin{figure}[H]
    \centering
    \captionsetup{justification=centering}
  
    \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{Sections/7Results/images/run2top1.jpg} 
    \caption{Top 1}
  
    \end{subfigure}
    \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{Sections/7Results/images/run3top2.jpg}\hfill
    \caption{Top 2}
    \end{subfigure}
    \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{Sections/7Results/images/run2top3.jpg}\hfill
      \caption{Top 3}
    \end{subfigure}
    \caption{Top 3 retrieved pictures for topic 9 on run 2}
  \end{figure}

  \newpage

  \subsection{Topic 9 Performance Analysis}

  Even tho the top 10 pictures are the ones that count for the performance evaluation of the run the top 3 pictures are already representative of the system efficiency. It is clear that for topic 9 the Run 1 achieved better efficiency, since the first 2 pictures are clearly from the topic. The third picture however does not belong to topic 9 since it is a picture of a person eating a lasagne alone but it is indeed a similar scenario.
  
  Run 2 however did not retrieved any single picture from topic 9 on the top 3 pictures, however the scenario is close. All of the 3 photos are representative of food being eaten. However, something to note is that run 2 confidence scores are higher than run 1, but run 1 achieved better practical results. Some possible reasons for this difference to occur can be :

  \begin{itemize}
    \itemsep0em
    \item The negative categories on run 1 might have decreased the confidence score on wrong pictures.
    \item The object detection system on Run 1 achieving better performance on these pictures than the run 2 object detection.
    \item The category weight distribution on run 2 decreasing the importance on some categories that were important on those images.
    \item The difference in the similarity score between the different visual concepts on each run might also impact the performance of the system.
  \end{itemize}



\section{Achieved Overall Performance Results}
\label{sec:perfomance_results}

Table \ref{table:2019} and table \ref{table:2020} show the achieved performance results in different runs for different systems that were obtained in the year 2019 and 2020 for the ImageCLEFlifelog LMRT subtask. 
\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}
\begin{table}[H]
    
    \centering
\begin{tabular}{ |P{4cm}|P{2.5cm}|P{2cm}|P{3cm}|  }
    \hline
    \multicolumn{4}{|c|}{\textbf{2019 Results}} \\
    \hline
    Team & System Type & Run Name & F1-measure@10 \\
    \hline
    UA.PT Bioinformatics  & automatic  & Run 1   &  0.016 \\
    UA.PT Bioinformatics  & automatic  & Run 2   &  0.026 \\
    UA.PT Bioinformatics  & automatic  & Run 3   &  0.027 \\
    UA.PT Bioinformatics  & automatic  & Run 4   &  0.027 \\
    UA.PT Bioinformatics  & automatic  & Run 5   &  0.036 \\
    UA.PT Bioinformatics  & automatic  & Run 6   &  0.057 \\
    \hline
    \multicolumn{4}{|c|}{\textbf{Best Results Achieved by a Team}} \\
    \hline
    HCMUS  & interactive  & Run 2   &  0.61 \\
    \hline        
    \end{tabular}
    \caption{Results obtained in 2019 from UA.PT Bioinformatics and the best team. }
    \label{table:2019}
\end{table}
\begin{table}[H]
    \centering
\begin{tabular}{ |P{4cm}|P{2.5cm}|P{2cm}|P{3cm}|  }   
    \hline
    \multicolumn{4}{|c|}{\textbf{2020 Results}} \\
    \hline
    Team & System Type & Run Name & F1-measure@10 \\
    \hline
    UA.PT Bioinformatics  & automatic  & Run 1   &  0.03 \\
    UA.PT Bioinformatics  & automatic  & Run 2   &  0.03 \\
    UA.PT Bioinformatics  & interactive  & Run 3  &  0.54 \\
    \hline
    \multicolumn{4}{|c|}{\textbf{Best Results Achieved by a Team}} \\
    \hline
    HCMUS  & interactive  & Run 10   &  0.81\\
    \hline       
    \end{tabular}
    \caption{Results obtained in 2020 from UA.PT Bioinformatics and the best team.}
    \label{table:2020}
\end{table}

From table \ref{table:2019} and table \ref{table:2020} it is already clear that having user interaction and visualization gives much better results than a fully automatic system.
